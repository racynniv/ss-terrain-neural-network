{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2be7c854",
   "metadata": {},
   "outputs": [],
   "source": [
    "#! shred -u setup_google_colab.py\n",
    "#! wget https://raw.githubusercontent.com/hse-aml/intro-to-dl/master/setup_google_colab.py -O setup_google_colab.py\n",
    "import setup_google_colab\n",
    "# please, uncomment the week you're working on\n",
    "# setup_google_colab.setup_week1()\n",
    "# setup_google_colab.setup_week2()\n",
    "# setup_google_colab.setup_week3()\n",
    "#setup_google_colab.setup_week4()\n",
    "# setup_google_colab.setup_week5()\n",
    "# setup_google_colab.setup_week6()\n",
    "\n",
    "# If you're using the old version of the course (check a path of notebook on Coursera, you'll see v1 or v2),\n",
    "# use setup_week2_old()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d12870fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62bf890e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ros/anaconda3/envs/keras-test/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/ros/anaconda3/envs/keras-test/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/ros/anaconda3/envs/keras-test/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/ros/anaconda3/envs/keras-test/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/ros/anaconda3/envs/keras-test/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/ros/anaconda3/envs/keras-test/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.10.0\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imread\n",
    "import scipy\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.layers as tfl\n",
    "from tensorflow.python.framework import ops\n",
    "\n",
    "%matplotlib inline\n",
    "np.random.seed(1)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "tf.test.gpu_device_name()\n",
    "\n",
    "print(tf.__version__)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9f0aa3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import Sequence\n",
    "\n",
    "from data_loader import load_batch\n",
    "\n",
    "class DataGenerator(Sequence):\n",
    "\n",
    "  def __init__(self, data, base_dir, down_scale=2, batch_size=16, noisy=False, noise_factor=0.5, shuffle=True):\n",
    "  \n",
    "    self.data = data\n",
    "    self.data_noisy = None\n",
    "    self.index = [i for i in range(self.data.shape[0])]\n",
    "    self.base_dir = base_dir\n",
    "    \n",
    "    self.batch_size = batch_size\n",
    "    self.noisy = noisy\n",
    "    self.noise_factor = noise_factor\n",
    "    self.shuffle = shuffle\n",
    "    self.on_epoch_end()\n",
    "    print(self.data.shape)\n",
    "    print(int(self.data.shape[0] / self.batch_size))\n",
    "\n",
    "  def __len__(self):\n",
    "    return int(self.data.shape[0] / self.batch_size)\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "    aug = np.zeros((self.batch_size,5))\n",
    "    batch = np.hstack((self.data[index:index+self.batch_size],aug))\n",
    "    img, accels, sds, tf, c_a = load_batch(batch,self.base_dir,down_scale=2)\n",
    "    img = np.expand_dims(img, axis=-1)\n",
    "    accels = np.expand_dims(accels[:,:,:,2], axis=-1)\n",
    "    tf = np.expand_dims(tf,axis=-1)\n",
    "    accels = np.multiply(accels,tf)\n",
    "    return [img, c_a,tf], accels\n",
    "\n",
    "  def on_epoch_end(self):\n",
    "    np.random.shuffle(self.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6bb3f86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15064\n",
      "16180\n",
      "15318\n",
      "15580\n",
      "15437\n",
      "77579\n",
      "15064\n",
      "62515\n",
      "15064\n",
      "77579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ros/anaconda3/envs/keras-test/lib/python3.6/site-packages/ipykernel_launcher.py:13: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "stamps = np.load(\"/media/ros/de64b3cc-d3b4-44e1-b807-300d3d8adb21/ss_terrain_nav/data/dirs_and_files.npy\",allow_pickle=True)\n",
    "length = len(stamps[0])+len(stamps[1])+len(stamps[2])+len(stamps[3])+len(stamps[4])\n",
    "print(len(stamps[0]))\n",
    "print(len(stamps[1]))\n",
    "print(len(stamps[2]))\n",
    "print(len(stamps[3]))\n",
    "print(len(stamps[4]))\n",
    "print(length)\n",
    "stamps = stamps.flatten()\n",
    "length = len(stamps[0])\n",
    "stamps = [stamps[0]+stamps[1]+stamps[2]+stamps[3]+stamps[4]]\n",
    "print(length)\n",
    "stamps = np.squeeze(np.array(stamps))\n",
    "train = stamps[length:]\n",
    "test = stamps[:length]\n",
    "print(len(train))\n",
    "print(len(test))\n",
    "print(len(stamps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c97345d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(62515, 2)\n",
      "3907\n",
      "(15064, 2)\n",
      "941\n"
     ]
    }
   ],
   "source": [
    "train_gen = DataGenerator(train, \"/media/ros/de64b3cc-d3b4-44e1-b807-300d3d8adb21/ss_terrain_nav/data/\", noisy=True)\n",
    "test_gen = DataGenerator(test, \"/media/ros/de64b3cc-d3b4-44e1-b807-300d3d8adb21/ss_terrain_nav/data/\", noisy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "337bbb55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolutional_model(img_shape, filters=[32,64,128,32], kernel_size=[3,3,3,3], \n",
    "                           pool_sizes=[2,2,2,2], pool_strides=[2,2,2,2]):\n",
    "    \"\"\"PCA's deeper brother. See instructions above. Use `code_size` in layer definitions.\"\"\"\n",
    "    H,W,C = img_shape\n",
    "    \n",
    "    img = tfl.Input(shape=img_shape)\n",
    "    P = img\n",
    "    \n",
    "    binary_tf = tfl.Input(shape=img_shape)\n",
    "    \n",
    "    accel = tfl.Input(shape=(6,))\n",
    "    \n",
    "    denom = np.prod(pool_strides)\n",
    "    \n",
    "    end_size_0 = int(img_shape[0] / denom)\n",
    "    end_size_1 = int(img_shape[1] / denom)\n",
    "    middle_size = end_size_0 * end_size_1 * filters[-1]\n",
    "    \n",
    "    for i in range(len(filters)):\n",
    "        Z = tfl.Conv2D(filters[i],kernel_size[i],padding='same')(P)\n",
    "        A = tfl.ReLU()(Z)\n",
    "        P = tfl.MaxPool2D(pool_size=(pool_sizes[i],pool_sizes[i]),\n",
    "                        strides=(pool_strides[i],pool_strides[i]),padding='same')(A)\n",
    "        \n",
    "    F = tfl.Flatten()(P)\n",
    "    \n",
    "    cat = tfl.concatenate([F,accel])\n",
    "    \n",
    "    D = tfl.Dense(middle_size,activation='relu')(cat)\n",
    "    \n",
    "    Z = tfl.Reshape((end_size_0,end_size_1,filters[-1]))(D)\n",
    "    \n",
    "    for i in range(len(filters)-2,-1,-1):\n",
    "        Z = tfl.Conv2DTranspose(filters=filters[i], kernel_size=(kernel_size[i],kernel_size[i]),\n",
    "                             strides=pool_strides[i], padding='same', activation='relu')(Z)\n",
    "        \n",
    "    Z = tfl.Conv2DTranspose(filters=1, kernel_size=(kernel_size[0],kernel_size[0]),\n",
    "                               strides=pool_strides[0],activation=None, padding='same')(Z)\n",
    "    \n",
    "    output = tfl.Multiply()([binary_tf,Z])\n",
    "    \n",
    "    model = tf.keras.Model(inputs=[img,accel,binary_tf],outputs=output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48128c37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 240, 320, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 240, 320, 32) 320         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu (ReLU)                    (None, 240, 320, 32) 0           conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 120, 160, 32) 0           re_lu[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 120, 160, 64) 18496       max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_1 (ReLU)                  (None, 120, 160, 64) 0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 60, 80, 64)   0           re_lu_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 60, 80, 128)  73856       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_2 (ReLU)                  (None, 60, 80, 128)  0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 30, 40, 128)  0           re_lu_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 30, 40, 64)   73792       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_3 (ReLU)                  (None, 30, 40, 64)   0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 15, 20, 64)   0           re_lu_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 19200)        0           max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            (None, 6)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 19206)        0           flatten[0][0]                    \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 19200)        368774400   concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 15, 20, 64)   0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose (Conv2DTranspo (None, 30, 40, 128)  73856       reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTrans (None, 60, 80, 64)   73792       conv2d_transpose[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTrans (None, 120, 160, 32) 18464       conv2d_transpose_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 240, 320, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTrans (None, 240, 320, 1)  289         conv2d_transpose_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "multiply (Multiply)             (None, 240, 320, 1)  0           input_2[0][0]                    \n",
      "                                                                 conv2d_transpose_3[0][0]         \n",
      "==================================================================================================\n",
      "Total params: 369,107,265\n",
      "Trainable params: 369,107,265\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "conv_model = convolutional_model((int(480/2), int(640/2), 1))\n",
    "conv_model.compile(optimizer='adam',\n",
    "                  loss='mse',\n",
    "                  metrics=['mse'])\n",
    "conv_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e81f5392",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will save model checkpoints here to continue training in case of kernel death\n",
    "model_filename = 'autoencoder.{0:03d}.hdf5'\n",
    "last_finished_epoch = None\n",
    "checkpoint_filepath = \"/media/ros/de64b3cc-d3b4-44e1-b807-300d3d8adb21/ss_terrain_nav/data/saved/{epoch:02d}-{val_loss:.2f}\"\n",
    "\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_filepath,\n",
    "                                                              monitor='val_loss',\n",
    "                                                              mode='min',\n",
    "                                                              verbose=1)\n",
    "\n",
    "#### uncomment below to continue training from model checkpoint\n",
    "#### fill `last_finished_epoch` with your latest finished epoch\n",
    "# from keras.models import load_model\n",
    "# s = reset_tf_session()\n",
    "# last_finished_epoch = 4\n",
    "# autoencoder = load_model(model_filename.format(last_finished_epoch))\n",
    "# encoder = autoencoder.layers[1]\n",
    "# decoder = autoencoder.layers[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f70851",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n"
     ]
    }
   ],
   "source": [
    "history = conv_model.fit_generator(generator=train_gen,\n",
    "                                    validation_data=test_gen,\n",
    "                                    validation_steps=32,\n",
    "                                    steps_per_epoch=32,\n",
    "                                    epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1261d2ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
